#source1:
#  type: 'OpenNI'
#  module: 'object_recognition_core.io.source'
#  parameters:
#    image_mode: 'SXGA_RES'
#    depth_mode: 'VGA_RES'
#    image_fps: 'FPS_15'
#    depth_fps: 'FPS_30'

#Use this instead to receive images via ROS
source1:
  type: RosKinect
  module: 'object_recognition_ros.io'
  parameters:
    rgb_frame_id: '/head_mount_xtion_optical_frame'
    rgb_image_topic: '/head_mount_xtion/rgb/image_raw'
    rgb_camera_info: '/head_mount_xtion/rgb/camera_info'
    depth_image_topic: '/head_mount_xtion/depth/image_raw'
    depth_camera_info: '/head_mount_xtion/depth/camera_info'
    #
    crop_enabled: True
    # #x_min: -0.4
    # #x_max: 0.4
    # #y_min: -1.0
    # #y_max: 0.2
    z_min: 0.3
    z_max: 1.5

sink1:
  type: 'Publisher'
  module: 'object_recognition_ros.io'
  parameters:
    #visualize: true
    object_ids: 'all'

sink2:
  type: Publisher
  module: 'object_recognition_ros.io'
  inputs: [source1]

voter1:
  type: 'Aggregator'
  module: 'object_recognition_core.io'
  outputs: [sink1]

pipeline1:
  type: 'TodDetector'
  module: 'object_recognition_tod.detector'
  inputs: [source1]
  outputs: [voter1, sink2]
  parameters:
    object_ids: "all"
    feature:
      type: ORB
      module: ecto_opencv.features2d
      #n_features: 5000
      # From the training file
      n_features: 1000
      n_levels: 3
      scale_factor: 1.2
    descriptor:
      type: ORB
      module: ecto_opencv.features2d
    search: 
      type: LSH
      module: ecto_opencv.features2d
      # key_size: 16
      # multi_probe_level: 1
      # n_tables: 10
      # radius: 35
      # ratio: 0.8
      # From the training file
      key_size: 24
      multi_probe_level: 2
      n_tables: 8
      radius: 55
      ratio: 0.8
    #n_ransac_iterations: 2500
    n_ransac_iterations: 1000
    min_inliers: 6
    sensor_error: 0.01
    db:
      type: CouchDB
      root: http://localhost:5984
      collection: object_recognition
